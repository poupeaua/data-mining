---
title: "TP1 - Data Mining"
output:
  html_document: default
  html_notebook: default
---

# Part one

### Question a)

```{r}

set.seed(0)

# creation of the vector
v = rnorm(6000*201, mean=0, sd=1)

# creation of the matrix 6000 lines and 201 columns
mat = matrix(data = v, nrow = 6000, ncol = 201)

# turn the matrix into a data frame
dataFrame = data.frame(mat)

# creation of the linear model
reg = lm(formula = X1 ~ . , data = dataFrame)

# uncomment that following part to see the summary of the regression
# summary(reg)

```

### Question b)

We assume that $y$ and $\forall i$, $\mu_i$ is a vector of size $6000$.

\begin{bmatrix}
y & \mu_1 & \mu_2 & \cdots & \mu_{200} \\
\end{bmatrix}

The associated equation is :

$y = \displaystyle \sum_{k=1}^{200} \beta_k \mu_k + \epsilon$

We expect that all $\beta_k$ are equals to $0$ because there is no correlation between vectors. We expect that $\epsilon$ is the only thing different than $0$, so $\epsilon$ is equal to $y$.

![](./brief_summary_1.png)

### Question c)

```{r}

# stock in the vector coef all the p-values
coef <- summary(reg)$coefficients[, 4]

# here we select the p-values assessed as significantly non-zero at level 5%
coef[coef < 0.05]

# count the number of those selected coefficients
length(coef[coef < 0.05])

```

This result is not expected at all since we computed random independant variables from the classic Gaussian model $\mathcal{N}(0, 1)$. All the $\beta_k$ should be equals to zero, however this is not the case because as there is many data, the linear model find some correlation between vectors that do not really exists.

# Part two



